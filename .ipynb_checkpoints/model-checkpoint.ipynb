{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "trainData=pd.read_csv('train.csv')\n",
    "testData = pd.read_csv(\"test.csv\")\n",
    "###############################################\n",
    "\n",
    "trainData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb87d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c0c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(s):\n",
    "    try:\n",
    "        d = eval(s)\n",
    "    except:\n",
    "        d = {}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1794522",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['belongs_to_collection','id'], axis=1, inplace=True)\n",
    "testData.drop(['belongs_to_collection','id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlabel( 'budget')\n",
    "plt.ylabel('revenu')\n",
    "plt.hist(trainData['budget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('displaying realtion between budget and revenu')\n",
    "plt.xlabel( 'budget')\n",
    "plt.ylabel('revenu')\n",
    "plt.scatter(x=trainData['budget'], y=trainData['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc49597",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainData[trainData['budget'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfb17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['budget'] = trainData['budget'].replace(0, trainData['budget'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39632a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainData[trainData['budget'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee998aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gn = pd.DataFrame(columns=['genre_name'])\n",
    "gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44baec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.concat([trainData, gn], axis=1)\n",
    "testData = pd.concat([testData, gn], axis=1)\n",
    "\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f13ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in trainData['genres']:\n",
    "    d = get_dict(i)\n",
    "    if d != {}:\n",
    "        trainData['genre_name'][j] = d[0]['name'] \n",
    "    else:\n",
    "         trainData['genre_name'][j] = np.NaN\n",
    "    j += 1\n",
    "\n",
    "j = 0\n",
    "for i in testData['genres']:\n",
    "    d = get_dict(i)\n",
    "    if d != {}:\n",
    "        testData['genre_name'][j] = d[0]['name'] \n",
    "    else:\n",
    "         testData['genre_name'][j] = np.NaN\n",
    "    j += 1\n",
    "trainData.drop(['genres'], axis=1, inplace=True)\n",
    "testData.drop(['genres'], axis=1, inplace=True)\n",
    "trainData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testData['homepage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['homepage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Homepage=pd.DataFrame(columns=['Homepage'])\n",
    "trainData=pd.concat([trainData,Homepage],axis=1)\n",
    "testData=pd.concat([testData,Homepage],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in trainData['homepage']:\n",
    "    if str(trainData['homepage'][j]) == 'nan':\n",
    "        trainData['Homepage'][j] = 0\n",
    "    else:\n",
    "        trainData['Homepage'][j] = 1\n",
    "    j += 1\n",
    "\n",
    "j = 0\n",
    "for i in testData['homepage']:\n",
    "    if str( testData['homepage'][j]) == 'nan':\n",
    "         testData['Homepage'][j] = 0\n",
    "    else:\n",
    "         testData['Homepage'][j] = 1\n",
    "    j += 1\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e00fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['homepage'], axis=1, inplace=True)\n",
    "testData.drop(['homepage'], axis=1, inplace=True)\n",
    "trainData[\"Homepage\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7027cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.violinplot(x='Homepage',y='revenue',data=trainData)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc22b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbd_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9721b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['imdb_id'], axis=1, inplace=True)\n",
    "testData.drop(['imdb_id'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83161c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_language\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b623923",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(trainData['original_language'][:5]):\n",
    "    print(i,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81459b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12, 9))\n",
    "sns.boxplot('original_language','revenue',data=trainData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in trainData['original_language']:\n",
    "    if(i=='en'):\n",
    "        trainData['Has_En']=1\n",
    "    else:\n",
    "        trainData['Has_En']=0\n",
    "for i in testData['original_language']:\n",
    "    if(i=='en'):\n",
    "        testData['Has_En']=1\n",
    "    else:\n",
    "        testData['Has_En']=0\n",
    "\n",
    "trainData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c137665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_title $ overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e41d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['original_title','overview'], axis=1, inplace=True)\n",
    "testData.drop(['original_title','overview'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75470f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#popularity\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['popularity'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d149397",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('popularity','revenue',data=trainData)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poster_path\n",
    "trainData.drop(['poster_path','original_language'], axis=1, inplace=True)\n",
    "testData.drop(['poster_path','original_language'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2cc6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c825eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#production_companies\n",
    "for i,e in enumerate(trainData[\"production_companies\"][:5]):\n",
    "    print(i,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b984d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_production_companies=pd.DataFrame(columns=['num_production_companies'])\n",
    "trainData=pd.concat([trainData,num_production_companies],axis=1)\n",
    "testData=pd.concat([testData,num_production_companies],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in trainData[\"production_companies\"]:\n",
    "    d=get_dict(i)\n",
    "    if len(d)!=0:\n",
    "        trainData['num_production_companies'][j]=len(d)\n",
    "    else:\n",
    "        trainData['num_production_companies'][j]=np.NaN\n",
    "    j+=1\n",
    "j=0\n",
    "for i in testData[\"production_companies\"]:\n",
    "    d=get_dict(i)\n",
    "    if len(d)!=0:\n",
    "        testData['num_production_companies'][j]=len(d)\n",
    "    else:\n",
    "        testData['num_production_companies'][j]=np.NaN\n",
    "    j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['production_companies'], axis=1, inplace=True)\n",
    "testData.drop(['production_companies'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947bc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"num_production_companies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d5bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='num_production_companies',y='revenue',data=trainData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e176d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"num_production_companies\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['num_production_companies'] = trainData['num_production_companies'].fillna(trainData['num_production_companies'].mode())\n",
    "\n",
    "testData['num_production_companies'] = testData['num_production_companies'].fillna(testData['num_production_companies'].mode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26abc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"num_production_companies\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c162932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#production_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c37633",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(trainData[\"production_countries\"][:5]):\n",
    "    print(i,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13104fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prodect_countries=pd.DataFrame(columns=[\"production_country\"])\n",
    "trainData=pd.concat([trainData,prodect_countries],axis=1)\n",
    "testData=pd.concat([testData,prodect_countries],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aba3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in trainData['production_countries']:\n",
    "    d = get_dict(i)\n",
    "    if d != {}:\n",
    "        if len(d) > 1:\n",
    "            countires = []\n",
    "            for k in range(len(d)):\n",
    "                countires.append(d[k]['name'])\n",
    "            if 'United States of America' in countires:\n",
    "                trainData['production_country'][j] = 'United States of America'\n",
    "        else:\n",
    "            trainData['production_country'][j] = d[0]['name']\n",
    "    else:\n",
    "        trainData['production_country'][j] = np.NaN\n",
    "    j += 1\n",
    "    \n",
    "j = 0\n",
    "for i in testData['production_countries']:\n",
    "    d = get_dict(i)\n",
    "    if d != {}:\n",
    "        if len(d) > 1:\n",
    "            countires = []\n",
    "            for k in range(len(d)):\n",
    "                countires.append(d[k]['name'])\n",
    "            if 'United States of America' in countires:\n",
    "                testData['production_country'][j] = 'United States of America'\n",
    "        else:\n",
    "            testData['production_country'][j] = d[0]['name']\n",
    "    else:\n",
    "        testData['production_country'][j] = np.NaN\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2deae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='production_country',y='revenue',data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_use_preduction=pd.DataFrame(columns=[\"is_use_preduction\"])\n",
    "trainData=pd.concat([trainData,is_use_preduction],axis=1)\n",
    "testData=pd.concat([testData,is_use_preduction],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in trainData[\"production_country\"]:\n",
    "    if i=='United States of America':\n",
    "        trainData['is_use_preduction'][j]=1\n",
    "    elif str(i)=='NaN':\n",
    "        trainData['is_use_preduction'][j]=np.NaN\n",
    "    else:\n",
    "        trainData['is_use_preduction'][j]=0\n",
    "    j+=1\n",
    "j=0\n",
    "for i in testData[\"production_country\"]:\n",
    "    if i=='United States of America':\n",
    "        testData['is_use_preduction'][j]=1\n",
    "    elif str(i)=='NaN':\n",
    "        testData['is_use_preduction'][j]=np.NaN\n",
    "    else:\n",
    "        testData['is_use_preduction'][j]=0\n",
    "    j+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e184e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['production_countries','production_country'], axis=1, inplace=True)\n",
    "testData.drop(['production_countries','production_country'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aead533",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['is_use_preduction'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b21d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#realse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e600c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['Day'] = trainData['release_date'].str.split('/', expand=True).replace(np.nan,-1)[0]\n",
    "trainData['Month'] = trainData['release_date'].str.split('/', expand=True).replace(np.nan,-1)[1]\n",
    "trainData['Year'] = trainData['release_date'].str.split('/', expand=True).replace(np.nan,-1)[2]\n",
    "trainData['Day'] = trainData['Day'].astype(int)\n",
    "trainData['Month'] = trainData['Month'].astype(int)\n",
    "trainData['Year'] = trainData['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a064d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Day',y='revenue',data=trainData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"Day\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Month',y='revenue',data=trainData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7af8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('Year','revenue',data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runtime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c233eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(trainData['runtime'][:5]):\n",
    "    print(i,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['runtime'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['runtime']=trainData['runtime'].fillna(trainData['runtime'].mean()).round()\n",
    "testData['runtime']=testData['runtime'].fillna(testData['runtime'].mean()).round()\n",
    "trainData['runtime'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc4865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12, 9))\n",
    "plt.scatter('runtime','revenue',data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c360c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spoken_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(trainData['spoken_languages'][:5]):\n",
    "    print(i,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62912904",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_spoken_languages = pd.DataFrame(columns=['number_of_spoken_languages'])\n",
    "trainData = pd.concat([trainData, number_of_spoken_languages], axis=1)\n",
    "testData = pd.concat([testData, number_of_spoken_languages], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in trainData['spoken_languages']:\n",
    "    d = get_dict(i)\n",
    "    if d != {}:\n",
    "        trainData['number_of_spoken_languages'][j] = len(d)\n",
    "    else:\n",
    "        trainData['number_of_spoken_languages'][j] = np.NaN\n",
    "    j += 1\n",
    "    \n",
    "j = 0\n",
    "for i in testData['spoken_languages']:\n",
    "    d = get_dict(i)\n",
    "    if d != {}:\n",
    "        testData['number_of_spoken_languages'][j] = len(d)\n",
    "    else:\n",
    "        testData['number_of_spoken_languages'][j] = np.NaN\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='number_of_spoken_languages', y='revenue', data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4357f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"number_of_spoken_languages\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['number_of_spoken_languages']=trainData['number_of_spoken_languages'].fillna(trainData['number_of_spoken_languages'].mean()).round()\n",
    "testData['number_of_spoken_languages']=testData['number_of_spoken_languages'].fillna(testData['number_of_spoken_languages'].mean()).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['spoken_languages'], axis=1, inplace=True)\n",
    "testData.drop(['spoken_languages'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562160ea",
   "metadata": {},
   "source": [
    "## LAST six features (Ahmed section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87297c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###status\n",
    "trainData['status'].value_counts()\n",
    "\n",
    "testData['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467873e0",
   "metadata": {},
   "source": [
    "### This feature is not useful most of them are already released "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['status'], axis=1, inplace=True)\n",
    "testData.drop(['status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a43d1",
   "metadata": {},
   "source": [
    "## tagline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e8e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 12))\n",
    "text = ' '.join(trainData['tagline'].fillna('').values)\n",
    "wordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\n",
    "plt.imshow(wordcloud)\n",
    "plt.title('Top words in tagline')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170a29f4",
   "metadata": {},
   "source": [
    "##  from this figure it's shown most films contains comedy  , drama related words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe8316e",
   "metadata": {},
   "source": [
    "## title will be dropped not important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07381a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.drop(['title'], axis=1, inplace=True)\n",
    "testData.drop(['title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980ca31",
   "metadata": {},
   "source": [
    "## keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData['Keywords'].value_counts()\n",
    "\n",
    "#trainData['Keywords'].astype(object)\n",
    "\n",
    "print('Number of Keywords in films')\n",
    "#needs to be revised\n",
    "trainData['Keywords'].apply(lambda x: len(str(x)) if x != {} else 0).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172fe7ad",
   "metadata": {},
   "source": [
    "## I will leave keywords for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can't make it work \n",
    "list_of_keywords = list(trainData['Keywords'].apply(lambda x: get_dict(x)))\n",
    "\n",
    "#trainData['Keywords'].astype(int)\n",
    "print('Number of Keywords in films')\n",
    "#trainData['Keywords'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)\n",
    "\n",
    "list_of_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d513bf1",
   "metadata": {},
   "source": [
    "## cast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355fefc",
   "metadata": {},
   "source": [
    "## temp code below don't care now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.genres= trainData.genres.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n",
    "trainData.head()\n",
    "\n",
    "trainData['id_geners'] = trainData['genres'].str.split(',', expand=True)[0]\n",
    "trainData['genres_Nam'] = trainData['genres'].str.split(',', expand=True)[1]\n",
    "trainData['genres_ID'] = trainData['id_geners'].str.split(':', expand=True)[1]\n",
    "trainData['genres_Name'] = trainData['genres_Nam'].str.split(':', expand=True)[1]\n",
    "#trainData['genres_Id'] = trainData['genres'].str.split(',', expand=True)[0]\n",
    "\n",
    "trainData['genres_Name'] = trainData['genres_Name'].str.replace('}', '')\n",
    "trainData['genres_Name'] = trainData['genres_Name'].str.replace(']', '')\n",
    "trainData.drop(['genres_Nam','id_geners','genres'], axis=1, inplace=True)\n",
    "\n",
    "trainData['genres_Name'] = trainData['genres_Name'].str.replace(']', '')\n",
    "trainData.head()\n",
    "\n",
    "trainData['Day'] = trainData['release_date'].str.split('/', expand=True).replace(np.nan,-1)[0]\n",
    "trainData['Month'] = trainData['release_date'].str.split('/', expand=True).replace(np.nan,-1)[1]\n",
    "trainData['Year'] = trainData['release_date'].str.split('/', expand=True).replace(np.nan,-1)[2]\n",
    "trainData['Day'] = trainData['Day'].astype(int)\n",
    "trainData['Month'] = trainData['Month'].astype(int)\n",
    "trainData['Year'] = trainData['Year'].astype(int)\n",
    "trainData.drop(['release_date','tagline','Keywords'] ,axis=1 ,inplace=True)\n",
    "trainData.head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def Feature_Encoder(trainData,cols):\n",
    "    for c in cols:\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(trainData[c].values))\n",
    "        trainData[c] = lbl.transform(list(trainData[c].values))\n",
    "    return trainData\n",
    "cols={'original_language','genres_Name','original_title','overview','poster_path','title'}\n",
    "trainData=Feature_Encoder(trainData,cols)\n",
    "trainData.head()\n",
    "\n",
    "# Converting nominal trainData to numberical trainData \n",
    "trainData[['status','tagline', \n",
    "      'original_language', \n",
    "      'production_companies', \n",
    "      'production_countries']] =trainData[['status', \n",
    "               'original_language', \n",
    "               'production_companies',\n",
    "               'production_countries']].astype('category')\n",
    "\n",
    "trainData['status'] = trainData['status'].cat.codes\n",
    "trainData['original_language'] = trainData['original_language'].cat.codes\n",
    "trainData['production_companies'] = trainData['production_companies'].cat.codes\n",
    "trainData['production_countries'] = trainData['production_countries'].cat.codes\n",
    "trainData.head()\n",
    "\n",
    "\n",
    "\n",
    "trainData['genersCount'] = trainData['spoken_languages'].str.count(',') + 1\n",
    "trainData.cast = trainData.cast.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n",
    "trainData.crew = trainData.crew.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n",
    "\n",
    "trainData['cast_count'] = trainData['cast'].str.count(',') + 1\n",
    "trainData['crew_count'] = trainData['crew'].str.count(',') + 1\n",
    "trainData.head()\n",
    "\n",
    "\n",
    "trainData['runtime']=trainData['runtime'].fillna(trainData['runtime'].mean())\n",
    "\n",
    "trainData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf3034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
